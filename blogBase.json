{"singlePage": [], "startSite": "", "filingNum": "", "onePageListNum": 15, "commentLabelColor": "#006b75", "yearColorList": ["#bc4c00", "#0969da", "#1f883d", "#A333D0"], "i18n": "EN", "themeMode": "manual", "dayTheme": "light", "nightTheme": "dark", "urlMode": "pinyin", "script": "", "style": "", "indexScript": "", "indexStyle": "", "bottomText": "", "showPostSource": 1, "iconList": {}, "UTC": 8, "rssSplit": "sentence", "exlink": {}, "needComment": 1, "title": "Magnus", "subTitle": "Sharing tech details about data engineering", "avatarUrl": "https://avatars.githubusercontent.com/u/118542956?v=4", "GMEEK_VERSION": "last", "postListJson": {"P2": {"htmlDir": "docs/post/Code Anatomy - Scheduling Data Pipelines with Apache Airflow.html", "labels": ["airflow"], "postTitle": "Code Anatomy - Scheduling Data Pipelines with Apache Airflow", "postUrl": "post/Code%20Anatomy%20-%20Scheduling%20Data%20Pipelines%20with%20Apache%20Airflow.html", "postSourceUrl": "https://github.com/Liang95869417/data-engineering/issues/2", "commentNum": 0, "wordCount": 3426, "description": "Scheduling and monitoring data pipelines are key responsibilities in data engineering, ensuring that data flows smoothly and efficiently through various systems. Apache Airflow stands out as a powerful tool for orchestrating these workflows programmatically. However, crafting efficient and effective Airflow DAGs (Directed Acyclic Graphs) can be a bit complex. In this post, we\u2019ll break down an Airflow DAG example to make its structure and functionality clear and understandable.\r\n\r\n# Basic Airflow DAG Example\r\nLet\u2019s start with a simple Airflow DAG that schedules a data pipeline. Here\u2019s the initial code:\r\n```\r\nfrom airflow import DAG\r\nfrom airflow.operators.empty import EmptyOperator\r\nfrom airflow.operators.python import PythonOperator\r\nfrom datetime import datetime, timedelta\r\n\r\n# Default arguments\r\ndefault_args = {\r\n    'owner': 'airflow',\r\n    'depends_on_past': False,\r\n    'start_date': datetime(2024, 1, 1),\r\n    'email_on_failure': False,\r\n    'email_on_retry': False,\r\n    'retries': 1,\r\n    'retry_delay': timedelta(minutes=5),\r\n}\r\n\r\n# Initialize the DAG\r\ndag = DAG(\r\n    'scheduling_data_pipeline',\r\n    default_args=default_args,\r\n    description='An example DAG for scheduling data pipeline',\r\n    schedule=timedelta(days=1),\r\n)\r\n\r\n# Define the tasks\r\nstart_task = EmptyOperator(task_id='start_task', dag=dag)\r\n\r\ndef print_hello():\r\n    return 'Hello world!'\r\n\r\nhello_task = PythonOperator(\r\n    task_id='hello_task',\r\n    python_callable=print_hello,\r\n    dag=dag,\r\n)\r\n\r\nend_task = EmptyOperator(task_id='end_task', dag=dag)\r\n\r\n# Set task dependencies\r\nstart_task >> hello_task >> end_task\r\n```\r\n# Understanding the Code\r\n## 1. Default Arguments\r\n```\r\ndefault_args = {\r\n    'owner': 'airflow',\r\n    'depends_on_past': False,\r\n    'start_date': datetime(2024, 1, 1),\r\n    'email_on_failure': False,\r\n    'email_on_retry': False,\r\n    'retries': 1,\r\n    'retry_delay': timedelta(minutes=5),\r\n}\r\n```\r\n- owner: The owner of the DAG.\r\n- depends_on_past: If set to True, tasks depend on the success of the previous task instance.\r\n- start_date: The date and time when the DAG should start running.\r\n- email_on_failure: Whether to send an email when a task fails.\r\n- email_on_retry: Whether to send an email when a task is retried.\r\n- retries: Number of times to retry a failed task.\r\n- retry_delay: Time delay between retries.\r\n\r\n## 2. Initializing the DAG\r\n```\r\ndag = DAG(\r\n    'scheduling_data_pipeline',\r\n    default_args=default_args,\r\n    description='An example DAG for scheduling data pipeline',\r\n    schedule=timedelta(days=1),\r\n)\r\n```\r\n- DAG: Defines the DAG with a unique name and the default arguments.\r\n- schedule: The interval at which the DAG should run. Here, it's set to run daily.\r\n\r\n## 3. Defining the Tasks\r\n```\r\nstart_task = EmptyOperator(task_id='start_task', dag=dag)\r\n\r\ndef print_hello():\r\n    return 'Hello world!'\r\n\r\nhello_task = PythonOperator(\r\n    task_id='hello_task',\r\n    python_callable=print_hello,\r\n    dag=dag,\r\n)\r\n\r\nend_task = EmptyOperator(task_id='end_task', dag=dag)\r\n```\r\n- EmptyOperator: A no-op operator that does nothing. Used here to signify the start and end of the pipeline.\r\n- PythonOperator: Executes a Python callable. In this case, it calls the print_hello function.\r\n\r\n## 4. Setting Task Dependencies\r\n```\r\nstart_task >> hello_task >> end_task\r\n```\r\n- This sets the order of task execution: start_task runs first, followed by hello_task, and finally end_task.\u3002", "top": 0, "createdAt": 1720184748, "style": "", "script": "", "ogImage": "https://avatars.githubusercontent.com/u/118542956?v=4", "createdDate": "2024-07-05", "dateLabelColor": "#bc4c00"}}, "singeListJson": {}, "labelColorDict": {"airflow": "#1D76DB", "bug": "#d73a4a", "duplicate": "#cfd3d7", "enhancement": "#a2eeef", "good first issue": "#7057ff", "help wanted": "#008672", "invalid": "#e4e669", "question": "#d876e3", "wontfix": "#ffffff"}, "displayTitle": "Magnus", "faviconUrl": "https://avatars.githubusercontent.com/u/118542956?v=4", "ogImage": "https://avatars.githubusercontent.com/u/118542956?v=4", "primerCSS": "<link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />", "homeUrl": "https://Liang95869417.github.io/data-engineering", "prevUrl": "disabled", "nextUrl": "disabled"}
